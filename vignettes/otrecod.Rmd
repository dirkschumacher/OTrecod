---
title: "OTrecod"
author: "Gregory Guernec"
date: "7/9/2019"
output: html_document
---
<!--
%\VignetteEngine{knitr::knitr}
%\VignetteIndexEntry{OTrecod}
-->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# THE OTrecod PACKAGE 

An application of the functions of the package on a real dataset      (07/2019)

```{r}
library(OTrecod)
```

## Example : The "samp.A" database of the StatMatch package. 

### Description 

(see `?samp.A` for more details)

This data set provides a limited number of variables observed at persons levels among those usually collected in the European Union Statistics on Income and Living Conditions Survey (EUâ€“SILC). 

It has been artificially generated as follows to show an application of the OTrecod package.

- 2 databases: `data` and `data`
- `c.net` (only in `data3`) and `c.neti.bis` (only in `data4`) coded voluntarily in 2 distinct encodings but represent the same information
- `c.neti` is a factor variable corresponding to the person's net income initially categorized in 7 classes of thousand of Euros
- `data3` and `data4` are composed of Subsets of specific and common covariates of different types, with incomplete information



# I. Preparing the dataset 

```{r}
library(StatMatch);

data(samp.A)
samp.A = samp.A[,c(1:11,13,12)]
dim(samp.A); names(samp.A)
```

```{r}
c.neti            = as.numeric(samp.A$c.neti)
samp.A$c.neti.bis = as.factor(ifelse(c.neti %in% c(1,2),1, 
                              ifelse(c.neti %in% c(3,4),2, 
                              ifelse(c.neti %in% c(5,6),3,4)))) 
data1 = samp.A[1:600,c(2:9,13)]
data2 = samp.A[601:1000,c(5:11,12,14)] #600 rows for data1 and 400 rows for data2
```

Insert the common covariate "marital" in 2 different types int the 2 database.

```{r}
data1$marital = as.numeric(data1$marital)
```

```{r}
# Insert eventually different levels in a common factor variable called "c.age"
# data2$c.age = as.character(data2$c.age)
# data2$c.age[data2$c.age %in% c("[16,34]","(34,44]")] = "[16,44]"
# data2$c.age = as.factor(data2$c.age)

# Add random NA in covariates (10% by covariates):
add_NA = function(DB,tx){
  DB_NA = DB
  for (j in 1:ncol(DB)){
     NA_indic = sample(1:nrow(DB),round(nrow(DB)*tx/100),replace=FALSE)
     DB_NA[NA_indic,j] = rep(NA,length(NA_indic))
  }
return(DB_NA)
}

set.seed(4036); data3 = add_NA(data1,10); data4 = add_NA(data2,10)

table(data3$c.neti) #----- OUTCOME: c.neti in 7 modalities in data3
```

```{r}
table(data4$c.neti.bis) #----- OUTCOME: c.neti.bis in 4 modalities in data4
```

```{r}
summary(data3)
```

```{r}
summary(data4)
```

# II. Detect possible problems between covariates in each databases

## Ability to detect risks of colinearity between variables

```{r}
library(car)
library(nnet)
library(ordinal)
sel_cov3 = OTrecod::select_var(data3,Y = "c.neti",type_Y = "ORD",threshX = 0.90,threshY = 0.90,thresh_vif = 10)
sel_cov3
```

```{r}
sel_cov4 = OTrecod::select_var(data4,Y = "c.neti.bis",type_Y = "ORD",threshX = 0.90,threshY = 0.90,thresh_vif = 10)
sel_cov4
```

The ouputs of the select_var() function for data3 and data4 suggests that the 
variables "sex" and "c.age" are good candidates for the data fusion

- In data4, the variable "n.income" should be exclude of the analysis because 
of its too strong association with the outcome.
- In data3, there is a risk of multicolinearity between the covariates "hsize5" 
and "hsize" and between "age" and "c.age". The function suggests to keep first 
the variables "c.age" and "sex" for the data fusion.
- In data4, the variable n.income seems too close to the outcome of interest. 
The question about its maintenance for the rest of the study should be worth asked.

We notice that the covariates "c.age" and "sex" explain the outcomes similarly in the two databases.

Based on the previous results, we decide  to remove the covariate "age" from data3: 

```{r}
data3 = data3[,setdiff(colnames(data3),"age")]
names(data3) 
```

We also remove the covariate "n.income" and "age" from data4:

```{r}
data4 = data4[,setdiff(colnames(data4),c("n.income","age"))]
names(data4)
```


# III. Prepare database for OT algorithm with the remaining covariates 

Using the mergedbs() function (requires the function "compare_lists","transfo_targets",and "imput_cov") 
Handle missing data by multiple imputation (MICE) 
Stores all the information in a single database 

```{r}
library(mice); library(plyr); library(missMDA) 

db_test  = merge_dbs(data3,data4,NAME_Y1 = "c.neti",NAME_Y2 = "c.neti.bis",
                     ordinal_DB1 = c(2,4,5,8), ordinal_DB2 = c(1,2,7), 
                     impute = "MICE",R_MICE = 3, seed_func = 4036)
summary(db_test)
```


```{r}
summary(db_test$DB_READY)
```

# IV. OT application on the remaining dataset 
#-------------------------------------------- 

# The OT function requires the prior execution of: "inst","average_from_group_closest" 

```{r}
library(rdist)  
library(dplyr); library(ROI); library(ROI.plugin.glpk) 
library(ompr); library(ompr.roi) 
```


# The OT function 

Implementation of the optimal transportation algorithm for data integration 
with or without relaxation of the constraints on marginal (OUTCOME and R-OUTCOME models) 

This function require the functions: 
- "instance",  
- "average_distance_to_closest": Compute the cost between pairs of outcomes as the average distance between 
  covariations of individuals with these outcomes, but considering only the percent closest neighbors. 
- "individual_from_group_closest" (indiv_method option = "sequential"): Sequentially assign the modality of the individuals 
  to that of the closest neighbor in the other base until the joint probability values are met. 
- "individual_from_group_optimal" (indiv_method option = "optimal"): Solve an optimization problem to get the individual 
    transport that minimizes total distance while satisfying the joint probability computed by the model by group. 


# ARGUMENTS: 

- percent_c   : Percent of closest neighbors taken in the computation of the costs 
- maxrelax    : Maximum percentage of deviation from expected probability masses (0 for the OUTCOME model, different for 0 for the R-OUTCOME model. Please consult the corresponding article) for more details. 
- norm        : Distance chosen for calculate the distances between categorical covariates.Equal to O (by default) for the Manhattan distance, equal to 1 for the Euclidean distance or equal to 2 for the Hammind distance. 
- indiv_method: Specifies the method used to get individual transport from group joint probabilities ("sequential" or "optimal"). Please consult the corresponding article for more details  
- full_disp   : If true, write the transported value of each individual; otherwise, juste write the number of missed transports 
- solver_disp : If false, do not display the outputs of the solver 


# OUTPUTS: 

- TIME_EXE   : running time of the function 
- TRANSPORT_A: Cost matrix corresponding to an estimation (i.e gamma) to the joint distribution of (YA,ZA) 
- TRANSPORT_B: Cost matrix corresponding to an estimation (i.e gamma) to the joint distribution of (YB,ZB) 
- estimatorZA: Estimators for the distributions of Z conditional to X and Y in base A  
- estimatorYB: Estimators for the distributions of Y conditional to X and Z in base B 
- DATA1_OT   : 1st database (A here) with individual OT prediction for "c.neti.bis" 
- DATA2_OT   : 2nd database (B here) with individual OT prediction for "c.neti" 


# Demo of an OUTCOME model (standard OT algorithm) 

```{r}
try4      = OT(db_test$DB_READY, percent_c = 1, maxrelax = 0, norm = 1, indiv_method="sequential", full_disp = FALSE, solver_disp = FALSE) 
summary(try4) 
```

```{r}
TRANSPORT_A = try4$TRANSPORT_A 
row.names(TRANSPORT_A) = levels(db_test$DB_READY[,2]) 
colnames(TRANSPORT_A)  = levels(db_test$DB_READY[,3]); TRANSPORT_A 
```

The prediction provided with OT corresponds to the "OTpred" variable of the two datasets DATA1_OT and DATA2_OT 

```{r}
head(try4$DATA1_OT) 
```

```{r}
head(try4$DATA2_OT) 
```

# The OT_joint function

Model where we directly compute the distribution of the outcomes for each individual or for sets of indviduals  
that similar values of covariates 

## ARGUMENTS 

- aggregate_tol : Quantify how much individuals'covariates must be close for aggregation 
- norm          : 1 or 2 for entropy depending on the type of regularization chosen (see article for more details) 
- percent_clos  : Percent of closest neighbors taken into consideration in regularization 
- lambda_reg    : Coefficient measuring the importance of the regularization term (corresponds toR-JOINT model for a value other than 0) 
- full_disp     : A boolean. If TRUE, write the transported value of each individual; otherwise, juste write the number of missed transports 
- solver_disp   : A boolean. If FALSE, do not display the outputs of the solver 


# OUTPUTS 

- TIME_EXE      : Running time of the function 
- GAMMA_A       : Cost matrix corresponding to an estimation (i.e gamma) to the joint distribution of (YA,ZA)  
- GAMMA_B       : Cost matrix corresponding to an estimation (i.e gamma) to the joint distribution of (YB,ZB) 
- estimatorZA   : Estimators for the distributions of Z conditional to X and Y in base A  
- estimatorYB   : Estimators for the distributions of Y conditional to X and Z in base B 
- DATA1_OT      : 1st database (A here) with individual OT prediction for "c.neti.bis" 
- DATA2_OT      : 2nd database (B here) with individual OT prediction for "c.neti" 

# A demo 
```{r}
try5 = OT_joint(db_test$DB_READY,maxrelax = 0.0, lambda_reg = 0.0, percent_clos = 0.2, norm = 1, aggregate_tol = 0.5, full_disp = FALSE, solver_disp = FALSE) 
```

```{r}
  summary(try5) 
```

# V. ASSESS THE PROXIMITY BETWEEN c.neti and c.neti.bis (predicted) BY GROUPING THE MODALITIES OF c.neti  

The function error_group() requires the prior execution of the following functions:  
family_part(), count_pos(); find_coord(), and try_group() 

Suppose that Y and Z are 2 categorical variables (ordered or not) where the number of levels of Y i bigger than the number of levels of Z 
The error_group() function researches the optimal grouping of modalities of Y to approach at best the distribution of Z to 
give an assessment of the proximity between the two encodings 

Demo on database A only: 

```{r}
Ypred = as.factor(try4$DATA1_OT$OTpred)
cc= error_group(Ypred,try4$DATA1_OT$Y1,ord=TRUE)
```

On database A, by grouping the modalities of the c.neti variable (7 levels) like 1 (best grouping) in 4 modalities (number of modalities of c.neti.bis) 
the dissimilarity rate between the 2 variables is less than 8%. 
