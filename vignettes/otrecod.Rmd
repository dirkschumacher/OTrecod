---
title: "OTrecod"
author: "Gregory Guernec"
date: "7/9/2019"
output:
  html_document: default
  pdf_document: default
---
<!--
%\VignetteEngine{knitr::knitr}
%\VignetteIndexEntry{OTrecod}
-->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
 
   

# THE OTrecod PACKAGE 

Here is an application of the functions of the package on a real dataset. 

```{r}
require(OTrecod)
```


# I. Description of the database

We used a subset of a dataset called "samp.A" from the StatMatch package. This dataset provides a limited number of variables observed at person’s levels among those usually collected in the European Union Statistics on Income and Living Conditions Survey (EU–SILC) (see `?samp.A` for more details).
We firstly introduced a recoding problem in this dataset to illustrate our method.
 

# Definition of the target variables

“c.neti” (Y) from samp.A is an ordered factor variable corresponding to the person's net income initially categorized in 7 classes of thousands of Euros: (-Inf,0] /(0,10] /(10,15]   (15,20] /(20,25] /(25,35] /(35, Inf]
Started from “c.neti”, we generated “c.neti.bis” (Z), a new ordered factor variable encoded into 4 categories by grouping categories from “c.neti” (1: grouped the class 1 and 2 of “c.neti”, 2: the class 3 and 4, 3:  the class 5 and 6, 4: corresponds to the 7th class only).
We finally separated the dataset in 2 independent subsets called data1 and data2 (no common subjects between these 2 datasets) and supposed that “c.neti” is only observed in data1, while “c.neti.bis” is only observed in data2. Thus, “c.neti” and “c.neti.bis” are not jointly observed but summarize a same target information encoded in 2 different scalings.

# Definition of the covariates

Each dataset (data1 and data2) is composed of a set of common variables to both dataset and a set of variables specific to it. Some common covariates may have the same label but not the same type.


It is also possible to add a part of missingness on variables before running the functions. We so introduce data3 and data4, 2 datasets corresponding to data1 and data2 with 10% of missing information randomly assigned to each variables (MCAR process, see the Rubin’s classification (1976) for more details).


```{r}
library(StatMatch);

data(samp.A)
samp.A = samp.A[,c(1:11,13,12)]
dim(samp.A); names(samp.A)
```

```{r}
c.neti            = as.numeric(samp.A$c.neti)
samp.A$c.neti.bis = as.factor(ifelse(c.neti %in% c(1,2),1, 
                              ifelse(c.neti %in% c(3,4),2, 
                              ifelse(c.neti %in% c(5,6),3,4)))) 
data1 = samp.A[1:600,c(2:9,13)]
data2 = samp.A[601:1000,c(5:11,12,14)] #600 rows for data1 and 400 rows for data2
```



```{r}
data1$marital = as.numeric(data1$marital)
```

```{r}
# Insert eventually different levels in a common factor variable called "c.age"
# data2$c.age = as.character(data2$c.age)
# data2$c.age[data2$c.age %in% c("[16,34]","(34,44]")] = "[16,44]"
# data2$c.age = as.factor(data2$c.age)

# Add random NA in covariates (10% by covariates):
add_NA = function(DB,tx){
  DB_NA = DB
  for (j in 1:ncol(DB)){
     NA_indic = sample(1:nrow(DB),round(nrow(DB)*tx/100),replace=FALSE)
     DB_NA[NA_indic,j] = rep(NA,length(NA_indic))
  }
return(DB_NA)
}

set.seed(4036); data3 = add_NA(data1,10); data4 = add_NA(data2,10)

table(data3$c.neti) #----- OUTCOME: c.neti in 7 modalities in data3
```

```{r}
table(data4$c.neti.bis) #----- OUTCOME: c.neti.bis in 4 modalities in data4
```

```{r}
summary(data3)
```

```{r}
summary(data4)
```


# II. Select covariates



```{r}
library(car)
library(nnet)
library(ordinal)
sel_cov3 = OTrecod::select_var(data3,Y = "c.neti",type_Y = "ORD",threshX = 0.90,threshY = 0.90,thresh_vif = 10)
sel_cov3
```

```{r}
sel_cov4 = OTrecod::select_var(data4,Y = "c.neti.bis",type_Y = "ORD",threshX = 0.90,threshY = 0.90,thresh_vif = 10)
sel_cov4
```

The ouputs of the select_var() function for data3 and data4 suggests that the variables "sex" and "c.age" are good candidates for the data fusion

- In data4, the variable "n.income" should be exclude of the analysis because of its too strong association with the outcome.

- In data3, there is a risk of multicolinearity between the covariates "hsize5" and "hsize" and between "age" and "c.age". The function suggests to keep first  the variables "c.age" and "sex" for the data fusion.

OToutcome accepts mixed covariates but OTjoint need covariates are in categories.

Even if we can't check the assumption that the distribution of the outcome Y or Z conditional to covariates are the same in the two databases, we notice that the covariates "c.age" and "sex" have both a positive association with the outcome in the two databases.

Based on the previous results, we decide  to remove the covariate "age" from data3: 

```{r}
data3 = data3[,setdiff(colnames(data3),"age")]
names(data3) 
```

We also remove the covariate "n.income" and "age" from data4:

```{r}
data4 = data4[,setdiff(colnames(data4),c("n.income","age"))]
names(data4)
```


# III. Preparing the databases

The mergedbs() function handles missing data by multiple imputation (MICE)  and stores all the information in a single database 

```{r}
library(mice); library(plyr); library(missMDA) 

db_test  = merge_dbs(data3,data4,NAME_Y1 = "c.neti",NAME_Y2 = "c.neti.bis",
                     ordinal_DB1 = c(2,4,5,8), ordinal_DB2 = c(1,2,7), 
                     impute = "MICE",R_MICE = 3, seed_func = 4036)
summary(db_test)
```


```{r}
summary(db_test$DB_READY)
```

# IV. OT application on the remaining dataset 


```{r}
library(rdist)  
library(dplyr); library(ROI); library(ROI.plugin.glpk) 
library(ompr); library(ompr.roi) 
```


# The OToutcome function 

Implementation of the optimal transportation algorithm for data integration with or without relaxation of the constraints on marginal.

The function OToutcome requires the functions:

- `instance`,  
- `average_distance_to_closest`: Compute the cost between pairs of outcomes as the average distance between covariates of individuals with these outcomes, but considering only the percent closest neighbors. 
- `individual_from_group_closest` (indiv_method option = "sequential"): Sequentially assign the modality of the individuals to that of the closest neighbor in the other base until the joint probability values are met. 
- `individual_from_group_optimal` (indiv_method option = "optimal"): Solve an optimization problem to get the individual transport that minimizes total distance while satisfying the joint probability computed by the model by group. 

# ARGUMENTS: 

- `percent_c`   : Percent of closest neighbors taken in the computation of the costs 
- `maxrelax`    : Maximum percentage of deviation from expected probability masses (0 for the OUTCOME model, different for 0 for the R-OUTCOME model. Please consult the corresponding article) for more details. 
- `norm`        : Distance chosen for calculate the distances between categorical covariates.Equal to O (by default) for the Manhattan distance, equal to 1 for the Euclidean distance or equal to 2 for the Hammind distance. 
- `indiv_method` : Specifies the method used to get individual transport from group joint probabilities ("sequential" or "optimal"). Please consult the corresponding article for more details  
- `full_disp`   : If true, write the transported value of each individual; otherwise, juste write the number of missed transports 
- `solver_disp` : If false, do not display the outputs of the solver 


# OUTPUTS: 

- `TIME_EXE`    : running time of the function 
- `TRANSPORT_A` : Cost matrix corresponding to an estimation (i.e gamma) to the joint distribution of ($Y^A$,$Z^A$) 
- `TRANSPORT_B` : Cost matrix corresponding to an estimation (i.e gamma) to the joint distribution of ($Y^B$,$Z^B$)
- `estimatorZA` : Estimators for the distributions of Z conditional to X and Y in base A  
- `estimatorYB` : Estimators for the distributions of Y conditional to X and Z in base B 
- `DATA1_OT`    : 1st database (A here) with individual OT prediction for "c.neti.bis" 
- `DATA2_OT`    : 2nd database (B here) with individual OT prediction for "c.neti" 




```{r}
try4      = OT(db_test$DB_READY, percent_c = 1, maxrelax = 0, norm = 1, indiv_method="sequential", full_disp = FALSE, solver_disp = FALSE) 
summary(try4) 
```

```{r}
TRANSPORT_A = try4$TRANSPORT_A 
row.names(TRANSPORT_A) = levels(db_test$DB_READY[,2]) 
colnames(TRANSPORT_A)  = levels(db_test$DB_READY[,3]); TRANSPORT_A 
```

The prediction provided with OT corresponds to the "OTpred" variable of the two datasets DATA1_OT and DATA2_OT 

```{r}
head(try4$DATA1_OT) 
```

```{r}
head(try4$DATA2_OT) 
```

# The OT_joint function

Model where we directly compute the distribution of the outcomes for each individual or for sets of indviduals  
that similar values of covariates 

## ARGUMENTS 

- `aggregate_tol` : Quantify how much individuals'covariates must be close for aggregation 
- `norm`          : 1 or 2 for entropy depending on the type of regularization chosen (see article for more details) 
- `percent_clos`  : Percent of closest neighbors taken into consideration in regularization 
- `lambda_reg`    : Coefficient measuring the importance of the regularization term (corresponds toR-JOINT model for a value other than 0) 
- `full_disp`     : A boolean. If TRUE, write the transported value of each individual; otherwise, juste write the number of missed transports 
- `solver_disp`   : A boolean. If FALSE, do not display the outputs of the solver 


# OUTPUTS 

- `TIME_EXE`      : Running time of the function 
- `GAMMA_A`       : Cost matrix corresponding to an estimation (i.e gamma) to the joint distribution of (YA,ZA)  
- `GAMMA_B`       : Cost matrix corresponding to an estimation (i.e gamma) to the joint distribution of (YB,ZB) 
- `estimatorZA`   : Estimators for the distributions of Z conditional to X and Y in base A  
- `estimatorYB`   : Estimators for the distributions of Y conditional to X and Z in base B 
- `DATA1_OT`      : 1st database (A here) with individual OT prediction for "c.neti.bis" 
- `DATA2_OT`      : 2nd database (B here) with individual OT prediction for "c.neti" 

# A demo 
```{r}
try5 = OT_joint(db_test$DB_READY,maxrelax = 0.0, lambda_reg = 0.0, percent_clos = 0.2, norm = 1, aggregate_tol = 0.5, full_disp = FALSE, solver_disp = FALSE) 
```

```{r}
  summary(try5) 
```

# V. Evaluate the quality of the data merging



Suppose that Y and Z are 2 categorical variables (ordered or not) where the number of levels of Y is bigger than the number of levels of Z. 
The error_group() function researches the optimal grouping of modalities of Y to approach at best the distribution of Z to 
give an assessment of the proximity between the two encodings. 

Demonstration on data3  only: 

```{r}
Ypred = as.factor(try4$DATA1_OT$OTpred)
cc= error_group(Ypred,try4$DATA1_OT$Y1,ord=TRUE)
```

By grouping subsequent levels, there are 20 possibilities to turn an ordered factor of 7 levels into an ordered factor of 4 levels. 
In the case of "c.neti", the possible groupings are detailed above in column 1 of the output of the error_group function (Each group separated by the "/" sign).
For each possibility, the rate of missclassified subjects in data3, between the predicted "c.neti.bis" and the recoded "c.neti" (in 4 levels), is detailed in the "error.rate" column of the output in ascending order.
The first grouping presents a dissimilarity rate between the 2 variables less than 8%, and corresponds to the grouping of levels initially performed to generate "c.neti.bis": This result reinforces the consistency of the prediction obtained by using the OT algorithm. 

